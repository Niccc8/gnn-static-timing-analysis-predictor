"""
OpenSTA Integration

Python wrapper for OpenSTA to generate timing labels from netlists.
Runs STA via TCL scripts and parses timing reports.
"""

import os
import subprocess
import json
import pandas as pd
from pathlib import Path
from typing import Dict, List, Optional
from loguru import logger


class STALabeler:
    """
    Interface to OpenSTA for timing label generation.
    
    Workflow:
        1. Generate TCL script for each netlist
        2. Run OpenSTA to extract slack values
        3. Parse timing reports to CSV labels
    """
    
    def __init__(self, opensta_bin: str = "opensta", tcl_template: Optional[str] = None):
        """
        Initialize STA labeler.
        
        Args:
            opensta_bin: Path to OpenSTA executable
            tcl_template: Path to custom TCL template (optional)
        """
        self.opensta_bin = opensta_bin
        self.tcl_template = tcl_template or self._get_default_tcl_template()
        
        # Verify OpenSTA is available
        try:
            result = subprocess.run(
                [self.opensta_bin, "-version"],
                capture_output=True,
                text=True,
                timeout=5
            )
            logger.info(f"OpenSTA found: {result.stdout.strip()}")
        except Exception as e:
            logger.warning(f"OpenSTA not found: {e}. Labeling will fail.")
    
    def label_netlist(
        self,
        verilog_file: str,
        library_file: str,
        top_module: str,
        clock_port: str = "clk",
        clock_period: float = 1.0,
        output_dir: str = "."
    ) -> pd.DataFrame:
        """
        Run STA on a netlist and extract timing labels.
        
        Args:
            verilog_file: Path to Verilog netlist
            library_file: Path to Liberty .lib file
            top_module: Top module name
            clock_port: Clock port name
            clock_period: Clock period in nanoseconds
            output_dir: Directory for output files
        
        Returns:
            DataFrame with columns: endpoint_name, slack_ps, is_violating
        """
        verilog_path = Path(verilog_file)
        if not verilog_path.exists():
            raise FileNotFoundError(f"Verilog file not found: {verilog_file}")
        
        library_path = Path(library_file)
        if not library_path.exists():
            raise FileNotFoundError(f"Library file not found: {library_file}")
        
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        # Generate TCL script
        tcl_file = output_path / f"{verilog_path.stem}_sta.tcl"
        self._generate_tcl_script(
            tcl_file,
            verilog_file,
            library_file,
            top_module,
            clock_port,
            clock_period,
            output_path
        )
        
        # Run OpenSTA
        logger.info(f"Running STA on {verilog_path.name}...")
        timing_report = output_path / f"{verilog_path.stem}_timing.json"
        
        try:
            result = subprocess.run(
                [self.opensta_bin, "-f", str(tcl_file)],
                capture_output=True,
                text=True,
                timeout=300,  # 5 minute timeout
                cwd=str(output_path)
            )
            
            if result.returncode != 0:
                logger.error(f"OpenSTA failed: {result.stderr}")
                return pd.DataFrame()
            
            logger.info(f"STA completed for {verilog_path.name}")
        except subprocess.TimeoutExpired:
            logger.error(f"STA timeout for {verilog_path.name}")
            return pd.DataFrame()
        
        # Parse timing report
        if timing_report.exists():
            return self._parse_timing_report(timing_report)
        else:
            logger.warning(f"Timing report not found: {timing_report}")
            return pd.DataFrame()
    
    def _generate_tcl_script(
        self,
        tcl_file: Path,
        verilog_file: str,
        library_file: str,
        top_module: str,
        clock_port: str,
        clock_period: float,
        output_path: Path
    ):
        """Generate TCL script for OpenSTA."""
        timing_json = output_path / f"{Path(verilog_file).stem}_timing.json"
        slack_txt = output_path / f"{Path(verilog_file).stem}_slack.txt"
        
        tcl_content = f"""
# OpenSTA TCL Script for Timing Analysis
# Auto-generated by STALabeler

# Read standard cell library
read_liberty {Path(library_file).absolute()}

# Read Verilog netlist
read_verilog {Path(verilog_file).absolute()}
link_design {top_module}

# Set timing constraints
create_clock -period {clock_period} [get_ports {{{clock_port}}}]

# Run timing analysis
report_checks -path_delay min_max -format json > {timing_json}

# Report worst slack
set wns [sta::worst_slack -max]
set tns [sta::total_negative_slack -max]
puts "Worst Negative Slack: $wns ns"
puts "Total Negative Slack: $tns ns"

# Report slack for all endpoints
set fh [open "{slack_txt}" w]
foreach_in_collection pin [all_outputs] {{
    set pin_name [get_property $pin full_name]
    set slack [sta::pin_slack $pin max]
    puts $fh "$pin_name,$slack"
}}
close $fh

exit
"""
        with open(tcl_file, 'w') as f:
            f.write(tcl_content)
        
        logger.debug(f"Generated TCL script: {tcl_file}")
    
    def _parse_timing_report(self, timing_report: Path) -> pd.DataFrame:
        """
        Parse OpenSTA JSON timing report.
        
        Returns:
            DataFrame with endpoint timing information
        """
        try:
            # Try parsing slack text file (simpler format)
            slack_file = timing_report.parent / f"{timing_report.stem.replace('_timing', '_slack')}.txt"
            
            if slack_file.exists():
                data = []
                with open(slack_file, 'r') as f:
                    for line in f:
                        if ',' in line:
                            parts = line.strip().split(',')
                            if len(parts) == 2:
                                endpoint = parts[0]
                                try:
                                    slack_ns = float(parts[1])
                                    slack_ps = slack_ns * 1000  # Convert to picoseconds
                                    is_violating = 1 if slack_ps <= 0 else 0
                                    data.append({
                                        "endpoint_name": endpoint,
                                        "slack_ps": slack_ps,
                                        "is_violating": is_violating
                                    })
                                except ValueError:
                                    continue
                
                df = pd.DataFrame(data)
                logger.info(f"Parsed {len(df)} endpoints, {df['is_violating'].sum()} violating")
                return df
            
            # Fallback: try parsing JSON (if OpenSTA supports it)
            with open(timing_report, 'r') as f:
                timing_data = json.load(f)
                # Parse JSON structure (format depends on OpenSTA version)
                # This is a placeholder - actual parsing depends on OpenSTA JSON format
                logger.warning("JSON parsing not implemented, using slack file instead")
                return pd.DataFrame()
                
        except Exception as e:
            logger.error(f"Error parsing timing report: {e}")
            return pd.DataFrame()
    
    @staticmethod
    def _get_default_tcl_template() -> str:
        """Return default TCL template."""
        return "default"  # Placeholder


if __name__ == "__main__":
    # Example usage
    import sys
    
    if len(sys.argv) < 4:
        print("Usage: python sta_labeler.py <verilog> <library> <top_module>")
        sys.exit(1)
    
    labeler = STALabeler()
    df = labeler.label_netlist(
        verilog_file=sys.argv[1],
        library_file=sys.argv[2],
        top_module=sys.argv[3],
        output_dir="sta_output"
    )
    
    if not df.empty:
        print(f"\nLabeling Results:")
        print(df.head(10))
        print(f"\nViolating endpoints: {df['is_violating'].sum()} / {len(df)}")
    else:
        print("Labeling failed")
